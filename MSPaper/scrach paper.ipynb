{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "# a = nlp(u'Nick is awesome! ')\n",
    "\n",
    "# displacy.render(a, style='ent', jupyter=True)\n",
    "\n",
    "# print(a.text)\n",
    "# for ent in a.ents:\n",
    "#     if ent.label_ == 'PERSON':\n",
    "#         a.text = a.text.replace(ent.text, '')\n",
    "        \n",
    "# print(a.text)\n",
    "# # displacy.render(a, style='ent', jupyter=True)\n",
    "# text = \"Nick was very communicative and gracious enough to transport me to and from the light rail upon my arrival and departure, and went the extra mile by leaving me maps, recommendations, and even printed out a bus route based on where I'd told him I planned on going.\"\n",
    "# do = nlp(text)\n",
    "# for ent in do.ents:\n",
    "#     print(ent.text, ent.label_)\n",
    "\n",
    "# # first sentence\n",
    "# newdoc = nlp(list(doc.sents)[0].text)\n",
    "# # displacy.render(newdoc, style='dep', jupyter=True, options={'distance': 90})\n",
    "# newdoc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions used to do sentence extraction.\n",
    "import spacy \n",
    "nlp = spacy.load('en')\n",
    "\n",
    "def parseSentence(doc):\n",
    "    return [sent for sent in doc.sents]\n",
    "\n",
    "def token_text(doc):\n",
    "    for token in doc:\n",
    "        print('\"' + token.text + '\"')\n",
    "        \n",
    "def see_entity(doc):\n",
    "    for ent in doc.ents:\n",
    "        print(ent.text, ent.label_)\n",
    "        \n",
    "# Uses stopwords for english from NLTK, and all puntuation characters by default\n",
    "r = Rake()\n",
    "r.get_ranked_phrases_with_scores\n",
    "\n",
    "def keyword_extraction(txtContent):\n",
    "    r.extract_keywords_from_text(txtContent)\n",
    "    return r.get_word_degrees()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in a.keys():\n",
    "#     if a[k]['total_score'] != 0:\n",
    "#         print(k, a[k]['total_score'], a[k]['sentence'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_score_sum(sen_keywords, aspect_keywords):\n",
    "#     score = 0\n",
    "#     for token1 in sen_keywords:\n",
    "#         for token2 in aspect_keywords:\n",
    "#             score += token1.similarity(token2)\n",
    "#     return score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
