{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****************************************************\n",
    "### The sentiment of sentence.\n",
    "### Stanford nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "from numpy.random import randn\n",
    "import numpy as np\n",
    "import re\n",
    "from pycorenlp import StanfordCoreNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_score7_hs_df = pd.read_csv(\"./Data/clean_hs_df_7.csv\", sep='\\t', encoding=\"utf-8\").drop(\"Unnamed: 0\", axis=1).set_index(['home_id'])\n",
    "clean_score8_hs_df = pd.read_csv(\"./Data/clean_hs_df_8.csv\", sep='\\t', encoding=\"utf-8\").drop(\"Unnamed: 0\", axis=1).set_index(['home_id'])\n",
    "clean_score9_hs_df = pd.read_csv(\"./Data/clean_hs_df_9.csv\", sep='\\t', encoding=\"utf-8\").drop(\"Unnamed: 0\", axis=1).set_index(['home_id'])\n",
    "clean_score10_hs_df = pd.read_csv(\"./Data/clean_hs_df_10.csv\", sep='\\t', encoding=\"utf-8\").drop(\"Unnamed: 0\", axis=1).set_index(['home_id'])\n",
    "loc_score7_hs_df = pd.read_csv(\"./Data/loc_hs_df_7.csv\", sep='\\t', encoding=\"utf-8\").drop(\"Unnamed: 0\", axis=1).set_index(['home_id'])\n",
    "loc_score8_hs_df = pd.read_csv(\"./Data/loc_hs_df_8.csv\", sep='\\t', encoding=\"utf-8\").drop(\"Unnamed: 0\", axis=1).set_index(['home_id'])\n",
    "loc_score9_hs_df = pd.read_csv(\"./Data/loc_hs_df_9.csv\", sep='\\t', encoding=\"utf-8\").drop(\"Unnamed: 0\", axis=1).set_index(['home_id'])\n",
    "loc_score10_hs_df = pd.read_csv(\"./Data/loc_hs_df_10.csv\", sep='\\t', encoding=\"utf-8\").drop(\"Unnamed: 0\", axis=1).set_index(['home_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = StanfordCoreNLP('http://localhost:9000')\n",
    "\n",
    "def stf_nlp_sentiment(text):\n",
    "    \n",
    "    if not text:\n",
    "        return None\n",
    "    else:\n",
    "        res = nlp.annotate(text,\n",
    "                           properties={\n",
    "                               'annotators': 'sentiment',\n",
    "                               'outputFormat': 'json'\n",
    "                           }) \n",
    "        return res[\"sentences\"][0][\"sentimentValue\"]\n",
    "\n",
    "def sentiment_summary(hs_df):\n",
    "\n",
    "    sentiment_summary_df = pd.DataFrame(index = hs_df.index, \n",
    "                                        columns=['num_sents',\n",
    "                                                 'num_neg_0.5', 'num_neut_0.5', 'num_pos_0.5', 'num_very_pos_0.5', 'num_very_neg_0.5',\n",
    "                                                 'num_neg_0.6', 'num_neut_0.6', 'num_pos_0.6', 'num_very_pos_0.6', 'num_very_neg_0.6',\n",
    "                                                 'num_neg_0.7', 'num_neut_0.7', 'num_pos_0.7', 'num_very_pos_0.7', 'num_very_neg_0.7'\n",
    "                                                ])\n",
    "    for idx in hs_df.index:\n",
    "        sentiment_summary_df.loc[idx][:6] = count_sentiment(hs_df, idx, 'sents_0.5')\n",
    "        sentiment_summary_df.loc[idx][6:11] = count_sentiment(hs_df, idx, 'sents_0.6')\n",
    "        sentiment_summary_df.loc[idx][-5:] = count_sentiment(hs_df, idx, 'sents_0.7')\n",
    "    \n",
    "    return sentiment_summary_df\n",
    "\n",
    "def count_sentiment(hs_df, idx, col):\n",
    "    \n",
    "    num_neg, num_neut, num_pos, num_very_pos, num_very_neg = 0, 0, 0, 0, 0\n",
    "    \n",
    "    for s in hs_df.loc[idx][col]:\n",
    "        sentiment_value = stf_nlp_sentiment(s)\n",
    "        \n",
    "        if sentiment_value:\n",
    "            if sentiment_value == '1':\n",
    "                num_neg += 1\n",
    "            elif sentiment_value == '2':\n",
    "                num_neut += 1\n",
    "            elif sentiment_value == '3':\n",
    "                num_pos += 1\n",
    "            elif sentiment_value== '4':\n",
    "                num_very_pos += 1\n",
    "            else:\n",
    "                num_very_neg += 1\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    if col.endswith('5'):\n",
    "        return [hs_df.loc[idx]['num_of_sents'], num_neg, num_neut, num_pos, num_very_pos, num_very_neg]\n",
    "    else:\n",
    "        return [num_neg, num_neut, num_pos, num_very_pos, num_very_neg]\n",
    "\n",
    "def sim_str_to_list(hs_df, col):\n",
    "    for idx in hs_df.index:\n",
    "        string = hs_df.loc[idx][col].strip('[').strip(']')\n",
    "        sim_string = re.split('\\', |\\\", ', string)\n",
    "        hs_df.at[idx, col] = [s.strip('\\ \\'').strip('\\\"') for s in sim_string]\n",
    "\n",
    "def get_sentiment_summary(hs_df):\n",
    "    sim_str_to_list(hs_df, 'sents_0.5')\n",
    "    sim_str_to_list(hs_df, 'sents_0.6')\n",
    "    sim_str_to_list(hs_df, 'sents_0.7')\n",
    "    return sentiment_summary(hs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_score7_sents_sentiment_df = get_sentiment_summary(clean_score7_hs_df)\n",
    "clean_score8_sents_sentiment_df = get_sentiment_summary(clean_score8_hs_df)\n",
    "clean_score9_sents_sentiment_df = get_sentiment_summary(clean_score9_hs_df)\n",
    "clean_score10_sents_sentiment_df = get_sentiment_summary(clean_score10_hs_df)\n",
    "\n",
    "loc_score7_sents_sentiment_df = get_sentiment_summary(loc_score7_hs_df)\n",
    "loc_score8_sents_sentiment_df = get_sentiment_summary(loc_score8_hs_df)\n",
    "loc_score9_sents_sentiment_df = get_sentiment_summary(loc_score9_hs_df)\n",
    "loc_score10_sents_sentiment_df = get_sentiment_summary(loc_score10_hs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_score7_sents_sentiment_df = pd.concat([clean_score7_hs_df, clean_score7_sents_sentiment_df], axis=1).drop(['num_sents'], axis=1)\n",
    "clean_score8_sents_sentiment_df = pd.concat([clean_score8_hs_df, clean_score8_sents_sentiment_df], axis=1).drop(['num_sents'], axis=1)\n",
    "clean_score9_sents_sentiment_df = pd.concat([clean_score9_hs_df, clean_score9_sents_sentiment_df], axis=1).drop(['num_sents'], axis=1)\n",
    "clean_score10_sents_sentiment_df = pd.concat([clean_score10_hs_df, clean_score10_sents_sentiment_df], axis=1).drop(['num_sents'], axis=1)\n",
    "\n",
    "loc_score7_sents_sentiment_df = pd.concat([loc_score7_hs_df, loc_score7_sents_sentiment_df], axis=1).drop(['num_sents'], axis=1)\n",
    "loc_score8_sents_sentiment_df = pd.concat([loc_score8_hs_df, loc_score8_sents_sentiment_df], axis=1).drop(['num_sents'], axis=1)\n",
    "loc_score9_sents_sentiment_df = pd.concat([loc_score9_hs_df, loc_score9_sents_sentiment_df], axis=1).drop(['num_sents'], axis=1)\n",
    "loc_score10_sents_sentiment_df = pd.concat([loc_score10_hs_df, loc_score10_sents_sentiment_df], axis=1).drop(['num_sents'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_score7_sents_sentiment_df.to_csv('./Data/sentiment_counts/clean_sents_stm_df_7.csv', sep='\\t', encoding='utf-8')\n",
    "clean_score8_sents_sentiment_df.to_csv('./Data/sentiment_counts/clean_sents_stm_df_8.csv', sep='\\t', encoding='utf-8')\n",
    "clean_score9_sents_sentiment_df.to_csv('./Data/sentiment_counts/clean_sents_stm_df_9.csv', sep='\\t', encoding='utf-8')\n",
    "clean_score10_sents_sentiment_df.to_csv('./Data/sentiment_counts/clean_sents_stm_df_10.csv', sep='\\t', encoding='utf-8')\n",
    "loc_score7_sents_sentiment_df.to_csv('./Data/sentiment_counts/loc_sents_stm_df_7.csv', sep='\\t', encoding='utf-8')\n",
    "loc_score8_sents_sentiment_df.to_csv('./Data/sentiment_counts/loc_sents_stm_df_8.csv', sep='\\t', encoding='utf-8')\n",
    "loc_score9_sents_sentiment_df.to_csv('./Data/sentiment_counts/loc_sents_stm_df_9.csv', sep='\\t', encoding='utf-8')\n",
    "loc_score10_sents_sentiment_df.to_csv('./Data/sentiment_counts/loc_sents_stm_df_10.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
