{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "from numpy.random import randn\n",
    "import numpy as np\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import rake_nltk\n",
    "from rake_nltk import Rake\n",
    "import nltk\n",
    "# from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "# use wordnet find the first level keywords\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**********************************************************************************************\n",
    "## Load data. \n",
    "### Merge sample homes and their reviews into one dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7202016</td>\n",
       "      <td>38917982</td>\n",
       "      <td>2015-07-19</td>\n",
       "      <td>28943674</td>\n",
       "      <td>Bianca</td>\n",
       "      <td>Cute and cozy place. Perfect location to every...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7202016</td>\n",
       "      <td>39087409</td>\n",
       "      <td>2015-07-20</td>\n",
       "      <td>32440555</td>\n",
       "      <td>Frank</td>\n",
       "      <td>Kelly has a great room in a very central locat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   home_id  review_id        date  reviewer_id reviewer_name  \\\n",
       "0  7202016   38917982  2015-07-19     28943674        Bianca   \n",
       "1  7202016   39087409  2015-07-20     32440555         Frank   \n",
       "\n",
       "                                            comments  \n",
       "0  Cute and cozy place. Perfect location to every...  \n",
       "1  Kelly has a great room in a very central locat...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Necessary Data: reviews\n",
    "reviews_df = pd.read_csv(\"./Data/reviews.csv\", encoding=\"utf-8\")\n",
    "reviews_df.columns = ['home_id', 'review_id', 'date', 'reviewer_id', 'reviewer_name', 'comments']\n",
    "reviews_df.dropna()\n",
    "reviews_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_id</th>\n",
       "      <th>property_type</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>scores_overall_rating</th>\n",
       "      <th>scores_accuracy</th>\n",
       "      <th>scores_cleanliness</th>\n",
       "      <th>scores_checkin</th>\n",
       "      <th>scores_communication</th>\n",
       "      <th>scores_location</th>\n",
       "      <th>scores_value</th>\n",
       "      <th>price_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>241032</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>$85.00</td>\n",
       "      <td>207</td>\n",
       "      <td>95.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>953595</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>$150.00</td>\n",
       "      <td>43</td>\n",
       "      <td>96.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   home_id property_type        room_type    price  number_of_reviews  \\\n",
       "0   241032     Apartment  Entire home/apt   $85.00                207   \n",
       "1   953595     Apartment  Entire home/apt  $150.00                 43   \n",
       "\n",
       "   scores_overall_rating  scores_accuracy  scores_cleanliness  scores_checkin  \\\n",
       "0                   95.0             10.0                10.0            10.0   \n",
       "1                   96.0             10.0                10.0            10.0   \n",
       "\n",
       "   scores_communication  scores_location  scores_value  price_int  \n",
       "0                  10.0              9.0          10.0         85  \n",
       "1                  10.0             10.0          10.0        150  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample1_df = pd.read_csv(\"./Data/sample_data_for_testing\", sep='\\t', encoding=\"utf-8\")\n",
    "sample1_df = sample1_df.drop(\"Unnamed: 0\", axis=1)\n",
    "sample1_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Total number of reviews: 68638\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_id</th>\n",
       "      <th>scores_cleanliness</th>\n",
       "      <th>review_id</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>241032</td>\n",
       "      <td>10.0</td>\n",
       "      <td>682061</td>\n",
       "      <td>Excellent all the way around. \\r\\n\\r\\nMaija wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>241032</td>\n",
       "      <td>10.0</td>\n",
       "      <td>691712</td>\n",
       "      <td>Maija's apartment was a wonderful place to sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>241032</td>\n",
       "      <td>10.0</td>\n",
       "      <td>702999</td>\n",
       "      <td>one of the most pleasant stays i've had in my ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   home_id  scores_cleanliness  review_id  \\\n",
       "0   241032                10.0     682061   \n",
       "1   241032                10.0     691712   \n",
       "2   241032                10.0     702999   \n",
       "\n",
       "                                            comments  \n",
       "0  Excellent all the way around. \\r\\n\\r\\nMaija wa...  \n",
       "1  Maija's apartment was a wonderful place to sta...  \n",
       "2  one of the most pleasant stays i've had in my ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the reviews and homes in the sample data.\n",
    "df1 = sample1_df[['home_id', 'scores_cleanliness']]\n",
    "df2 = reviews_df[['home_id', 'review_id', 'comments']]\n",
    "\n",
    "print(\"-\" * 40 \n",
    "      + '\\nTotal number of reviews: ' \n",
    "      + str(sample1_df['number_of_reviews'].sum()) \n",
    "      + \"\\n\" + \"-\" * 40)\n",
    "\n",
    "sample1_rh_df = pd.merge(df1, df2, on=\"home_id\")\n",
    "sample1_rh_df.head(3)\n",
    "\n",
    "# sample1_rh_df.stack()[0].comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**********************************************************************************************\n",
    "## Analyze `cleanliness` aspect\n",
    "### Use the selected aspect keywords to analyze reviews \n",
    "**********************************************************************************************\n",
    "### Brief summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************\n",
      "There are:\n",
      "----------------------------------------\n",
      "2225 Airbnb homes in total.\n",
      "----------------------------------------\n",
      "68638 reviews in total.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# sample2_rh_df is a copy of sample1_rh_df to \n",
    "# in case unexpected modification for original data.\n",
    "sample2_rh_df = sample1_rh_df\n",
    "print('*' * 40 + '\\nThere are:\\n' + '-' * 40)\n",
    "print(str(len(sample2_rh_df.groupby('home_id'))) + \" Airbnb homes in total.\\n\" + '-' * 40)\n",
    "print(str(len(sample2_rh_df)) + \" reviews in total.\\n\" + '-' * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number of homes</th>\n",
       "      <th>number of reveiws</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_cleanliness</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>23</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>20</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>113</td>\n",
       "      <td>2813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>512</td>\n",
       "      <td>16571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>1549</td>\n",
       "      <td>48904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    number of homes  number of reveiws\n",
       "scores_cleanliness                                    \n",
       "3.0                               1                  2\n",
       "4.0                               4                  9\n",
       "5.0                               3                 17\n",
       "6.0                              23                 86\n",
       "7.0                              20                236\n",
       "8.0                             113               2813\n",
       "9.0                             512              16571\n",
       "10.0                           1549              48904"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group by scores_cleanliness\n",
    "df1 = pd.DataFrame(sample2_rh_df.groupby(['scores_cleanliness'])['home_id'].nunique())\n",
    "df2 = pd.DataFrame(sample2_rh_df.groupby(['scores_cleanliness'])['review_id'].nunique())\n",
    "summary_df = pd.merge(df1, df2, on = 'scores_cleanliness')\n",
    "summary_df.columns = ['number of homes', 'number of reveiws']\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**********************************************************************************************\n",
    "### Chose one cleanliness score to do further analysis.\n",
    "#### Here I choose Airbnb homes with cleanliness score as `8.0` to do the \"pliot test\". \n",
    "#### As in above table, there are `113` homes with `2813` reviews in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "home_id\n",
       "258571     278\n",
       "719233     255\n",
       "882274     189\n",
       "1039766    147\n",
       "1815304    139\n",
       "1950446    136\n",
       "815017     136\n",
       "1100714    134\n",
       "1773803    124\n",
       "3316219    106\n",
       "Name: comments, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample2_rh_df[sample2_rh_df.scores_cleanliness == 8.0].groupby(['home_id'])['comments'].count().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*******\n",
    "### Here, the logic of determine the aspect that a sentence talking about is:\n",
    "\n",
    "* `aspect_keywords_dic` is a dictionary contains aspects and their relevant keywords.**\n",
    "\n",
    "* Firstly, I use the Word2Vec similarity algorithm to count the similarity score between two words.\n",
    "\n",
    "* For each sentence, the aspect-similarity-score will `+1` when one word in it has the word-similarity-score with any word in keyword list lager than `0.7`(this number can change based on needs). \n",
    "\n",
    "* I tried use the total scores of all vectors(word-in-sentence to word-in-keywords), however, the results are very strange."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_keywords_dic = {\n",
    "    'location': ['region', 'locality', 'neck_of_the_woods', 'location', 'vicinity',\n",
    "                 'neighbourhood', 'neighborhood'],\n",
    "    'cleanliness': ['tidy_up', 'straighten_out', 'cleanliness', 'clean', \n",
    "                    'neaten', 'square_away', 'straighten', 'clean_house', 'make_clean', \n",
    "                    'tidy', 'houseclean', 'clean_up', 'scavenge',\n",
    "                   'soiled', 'unclean', 'colly', 'bemire', 'uncleanliness', 'soil', 'begrime',\n",
    "                    'grime', 'untidy', 'dirty']\n",
    "}\n",
    "\n",
    "def sents_sim_score(doc, aspect, sim):\n",
    "    \n",
    "    sent_asp_sim_score_df = pd.DataFrame(columns = ['sentence_id', 'aspect_sim_score', 'text'])\n",
    "    \n",
    "    aspect_keywords = nlp(' '.join(aspect_keywords_dic[aspect]))\n",
    "\n",
    "    # I tried use the total scores of all vectors, however, the results are very strange.\n",
    "    # So, I tried to use the count of the words in a sentance \n",
    "    # that with lager than 0.7 similarity score to determine the relevance.\n",
    "    \n",
    "    for which_sen in range(len(list(doc.sents))):\n",
    "        \n",
    "        new_doc = list(doc.sents)[which_sen].text        \n",
    "        sen_keywords = nlp(new_doc)\n",
    "        aspect_sim_score = compute_score(sen_keywords, aspect_keywords, sim)\n",
    "        sent_asp_sim_score_df.loc[which_sen] = [which_sen, aspect_sim_score, new_doc]\n",
    "    \n",
    "    return sent_asp_sim_score_df\n",
    "\n",
    "def compute_score(sen_keywords, aspect_keywords, sim):\n",
    "    count = 0\n",
    "    for token1 in sen_keywords:\n",
    "        for token2 in aspect_keywords:\n",
    "            if token1.similarity(token2) >= sim:\n",
    "                count += 1 \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_of_homes_with_score(score, aspect):\n",
    "    \n",
    "    score_dic = {}\n",
    "    score_df = sample2_rh_df[sample2_rh_df.scores_cleanliness == score]\n",
    "    score_series = score_df.groupby(['home_id'])['review_id'].count()\n",
    "    \n",
    "    summary_df = pd.DataFrame(columns=['home_id','num_of_reviews', 'num_of_sents', \n",
    "                                           'aspect', 'num_of_sents_0.5', \n",
    "                                           'num_of_sents_0.6', 'num_of_sents_0.7'])\n",
    "\n",
    "    for i in range(len(score_series)):\n",
    "#     for i in range(4):\n",
    "        \n",
    "        print(\"home\" + str(i))\n",
    "        home_id = score8_series.index[i]\n",
    "        num_of_reviews = score_series.values[i]\n",
    "        num_of_sents = count_sents(home_id)[0]\n",
    "        num_of_sents_05 = home_sents_process(home_id, aspect, 0.5)[0]\n",
    "        num_of_sents_06 = home_sents_process(home_id, aspect, 0.6)[0]\n",
    "        num_of_sents_07 = home_sents_process(home_id, aspect, 0.7)[0]\n",
    "\n",
    "        summary_df.loc[i] = [home_id, num_of_reviews, num_of_sents, aspect, num_of_sents_05, \n",
    "                             num_of_sents_06, num_of_sents_07]\n",
    "\n",
    "    return summary_df\n",
    "\n",
    "def count_sents(home_id):\n",
    "    # all comments together\n",
    "    comments = ''.join(list(sample2_rh_df[sample2_rh_df.home_id == home_id].comments))\n",
    "    doc = nlp(comments)\n",
    "    \n",
    "    return len(list(doc.sents)), doc\n",
    "    \n",
    "def home_sents_process(home_id, aspect, sim):\n",
    "    \n",
    "    doc = count_sents(home_id)[1]\n",
    "    sents_score_dic = sents_sim_score(doc, aspect, sim)\n",
    "    home_asp_sents = sents_score_dic[sents_score_dic['aspect_sim_score'] != 0].text\n",
    "    \n",
    "    return len(home_asp_sents), home_asp_sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see the result of homes with cleanliness score `8.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "home0\n",
      "home1\n",
      "home2\n",
      "home3\n",
      "home4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-8dac7ff9cdae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore8_homes_reviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummary_of_homes_with_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cleanliness'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mscore8_homes_reviews\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-106-ec50fd479401>\u001b[0m in \u001b[0;36msummary_of_homes_with_score\u001b[0;34m(score, aspect)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mnum_of_sents_05\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhome_sents_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhome_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mnum_of_sents_06\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhome_sents_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhome_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mnum_of_sents_07\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhome_sents_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhome_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         summary_df.loc[i] = [home_id, num_of_reviews, num_of_sents, aspect, num_of_sents_05, \n",
      "\u001b[0;32m<ipython-input-106-ec50fd479401>\u001b[0m in \u001b[0;36mhome_sents_process\u001b[0;34m(home_id, aspect, sim)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_sents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhome_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0msents_score_dic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msents_sim_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mhome_asp_sents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msents_score_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msents_score_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'aspect_sim_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-98-1bb00bf0a778>\u001b[0m in \u001b[0;36msents_sim_score\u001b[0;34m(doc, aspect, sim)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mnew_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwhich_sen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0msen_keywords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_doc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0maspect_sim_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msen_keywords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspect_keywords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0msent_asp_sim_score_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwhich_sen\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mwhich_sen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspect_sim_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_doc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-98-1bb00bf0a778>\u001b[0m in \u001b[0;36mcompute_score\u001b[0;34m(sen_keywords, aspect_keywords, sim)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtoken1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msen_keywords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtoken2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maspect_keywords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mtoken1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                 \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtoken.pyx\u001b[0m in \u001b[0;36mspacy.tokens.token.Token.similarity\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mtoken.pyx\u001b[0m in \u001b[0;36mspacy.tokens.token.Token.vector_norm.__get__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial)\u001b[0m\n\u001b[1;32m     34\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[1;32m     35\u001b[0m          initial=_NoValue):\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "score8_homes_reviews = summary_of_homes_with_score(8.0, 'cleanliness')\n",
    "score8_homes_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**********************************************************************************************\n",
    "### Try a small sample: home 258571 which has 278 number of comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "There are in total 1478 sentences in these 278 comments.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "comment258571 = ''.join(list(sample2_rh_df[sample2_rh_df.home_id == 258571].comments))\n",
    "doc = nlp(comment258571)\n",
    "\n",
    "print(\"-\" * 80 +\n",
    "      \"\\nThere are in total \" \n",
    "      + str(len(list(doc.sents))) \n",
    "      + \" sentences in these 278 comments.\\n\" \n",
    "      + \"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>aspect_sim_score</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>The apartment was exactly what we had expected...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>right in the heart of Capitol Hill, just off B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Nick was prompt and very friendly, reachable e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>The apartment was clean and quiet.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>I would certainly stay here again.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentence_id aspect_sim_score  \\\n",
       "0           0                0   \n",
       "1           1                0   \n",
       "2           2                0   \n",
       "3           3                1   \n",
       "4           4                0   \n",
       "\n",
       "                                                text  \n",
       "0  The apartment was exactly what we had expected...  \n",
       "1  right in the heart of Capitol Hill, just off B...  \n",
       "2  Nick was prompt and very friendly, reachable e...  \n",
       "3               The apartment was clean and quiet.    \n",
       "4               I would certainly stay here again.    "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home258571_sent_score = sents_sim_score(doc, 'cleanliness', 0.7)\n",
    "home258571_sent_scxore.head(5)\n",
    "# home258571_cleanliness_text = [home258571_sent_score[k]['sentence'] for k in home258571_sent_score.keys() if home258571_sent_score[k]['aspect_sim_score'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = home258571_sent_score[home258571_sent_score['aspect_sim_score'] != 0].text\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*******************\n",
    "\n",
    "### Result summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "627"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(home258571_cleanliness_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "There are 627/1478 sentences talking about the cleanliness aspect.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"-\" * 80\n",
    "      + \"\\nThere are \" \n",
    "      + str(len(home258571_cleanliness_text))\n",
    "      + \"/\"\n",
    "      + str(len(list(doc.sents)))\n",
    "      + \" sentences talking about the cleanliness aspect.\\n\"\n",
    "      + \"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The apartment was clean and quiet.  ',\n",
       " 'Great host, comfy, clean room with all you need in the most buzzing part of Seattle.  ',\n",
       " 'Overall, incredibly good value and highly recommended!!The apartment was clean and really nice.  ',\n",
       " 'Thanks!Nick does his best to provide the things you would need for a comfortable stay (clean sheets, towels, plates, wifi!!).',\n",
       " 'Even though its at the back of the building and the giant living room windows look out onto an odd stone alley, the alley is clean and there is something very zen about the view from the living room.  ',\n",
       " 'the kitchen needed a good scrubbing - it was dirty.  ',\n",
       " 'The apartment was a little on the small side - so probably better for just 2 people - but it was clean and in a great neighborhood.',\n",
       " 'Super clean and convenient.',\n",
       " 'Comfortable, clean and quiet the apartment had just about everything you could ask for.  ',\n",
       " 'The apartment was clean and comfortable, and you absolutely cannot beat the location!',\n",
       " 'The apartment was clean, well furnished and more than enough for what we needed.',\n",
       " 'His apartment was very cozy, tidy, and space efficient since it was only the two of us staying there.  ',\n",
       " 'Apartment was tidy and had everything we needed.',\n",
       " 'The apartment was clean, private, a perfect home away from home.',\n",
       " 'It was very clean and comfortable, and located within easy walking distance of the Capital Hill bar scene.',\n",
       " 'My only complaint and reason for rating this apartment three stars is that it needs to be thoroughly cleaned.  ',\n",
       " 'The bathroom was very dirty with dust and hair in the tub and on the floor.   ',\n",
       " 'Thanks again!The apartment was clean, cozy, well-stocked, and most importantly, very close to the downtown area!',\n",
       " 'Apartment is cozy and clean.',\n",
       " 'The place was clean and comfortable, and the location is ideal for those wanting to get around on foot, and Bauhaus Coffee (where you can get a cuppa and a Top Pot donut) is at the end of the block!',\n",
       " 'The place is quiet and clean.',\n",
       " 'The apartment was clean and exactly what I was looking for.',\n",
       " 'Clean and wonderful place to stay!',\n",
       " 'Apartment was clean and as advertised.',\n",
       " 'Everything was clean for the most part and the place was quiet/warm enough during our stay (December).',\n",
       " 'The place was nice, clean, and well-kept, but the best thing about it was the location.',\n",
       " 'The apartment was clean and cozy and in a great location.  ',\n",
       " \"Thanks guys!It's good value and a great location (we walked everywhere) and the host was very helpful in allowing us to check in early, but the place was not clean (perhaps this was due to our early check in, though much of the dirt had been there for some time).\",\n",
       " 'One downside, however, was that i found the unit not clean enough.  ',\n",
       " 'We have stayed in a few Airbnb accommodations in the last year and in general this place was not as clean as we have come to expect from Airbnb.',\n",
       " \"Some maintenance issues and a degree of run-downness likely due to the building age and quality (outside of Nick's hands) may have contributed to this perception, though some of these problems should be easy fixes (such as some general cleanliness, fixing the bed and shower head).\\r\\n\",\n",
       " 'I stayed here for 2 nights and found it clean, comfortable and location fantastic.',\n",
       " 'great location, cozy, clean, and comfortable.',\n",
       " 'The complex and apartment were a little old and worn, but clean and in a great area.  ',\n",
       " 'The good bit is the flat is very clean and in a convenient location to walk everywhere.',\n",
       " \"Wouldn't take much to bring it up to scratch - matching china, matching towels, a hand towel and drying up (website hidden) was hopeless\",\n",
       " 'Otherwise the place was clean, safe and conveniently located.  ',\n",
       " 'Apartment was clean and not cluttered.',\n",
       " 'The apartment was nice and roomy, clean and well supplied.',\n",
       " 'She was quick to respond to our requests, such as needing hand towels and wash cloths, a rubber mat for the shower and installing a converter box so that we could watch local television channels.  \\r\\n',\n",
       " 'The apartment could use a deep cleaning.',\n",
       " \"The apartment is not spotless clean but it's clean enough - for instance, there was some food in the fridge from the prior tenants.  \",\n",
       " 'Cozy bedroom, clean bathroom, good price and perfect location.',\n",
       " 'It was clean, neat and comfortable.',\n",
       " 'The place was really nice and clean..',\n",
       " \"pretty sure the sheets weren't clean which is the worst, we both slept in our clothes every night\\r\\n\",\n",
       " 'but I was at least hoping the bed would be clean and not rock hard....',\n",
       " 'The apartment was very clean and Nick was very accomodating!The',\n",
       " 'The apartment was clean and the bed and pillows were comfortable.',\n",
       " 'The apartment was clean and everything worked.  ',\n",
       " 'In all, good value and great location , but a bit dirty and the photos make it seem nicer, brighter and larger than the apartment really is.\\n\\n',\n",
       " 'The apartment needed some cleaning.',\n",
       " 'There was quite a bit of dust built up on most of the appliances and when we checked the bed there were a few hairs on the sheets, so we decided to wash them before sleeping on the bed.',\n",
       " 'When we checked out we tried to leave it clean.',\n",
       " 'Clean space, on the darker and older side, and the bed is very noisy but overall it was perfect for the price and you cannot beat the location.',\n",
       " \"Apartment was clean and close to the Capital Hill scene!For the location, it's hard to beat the price and convenience of this spot.\",\n",
       " 'The clean rooms were ample for 2, the bed was comfortable and great coffee was just around the corner.',\n",
       " 'The apartment was clean, and there is also a well-equipped kitchen.',\n",
       " 'There were a few issues at check in due to the cleaning service but Nicole was responsive and had a place for us to store our bags until the room was ready.',\n",
       " 'This apartment was clean, and in an awesome location.',\n",
       " 'The appartment was so clean, quiet and nicely fitted out. \\n\\n',\n",
       " 'Clean and simple place.',\n",
       " 'The apartment is very clean and neat, just as is described.',\n",
       " 'The apartment is in need of a deep cleaning.',\n",
       " 'Great and very clean space in a perfect location!  ',\n",
       " 'Clean comfortable apartment.',\n",
       " 'The apartment was clean and had everything I needed.',\n",
       " 'The location is ideal for neat local spots like Melrose market or walking up the Pine-Pike corridor.',\n",
       " 'Bed was extremely comfortable and the apartment very clean.',\n",
       " 'floor and bed cover clean condition is so so. \\n',\n",
       " 'The neighborhood is perfectly located, and the apartment was clean and well-furnished.  ',\n",
       " 'I am by no means a \"clean freak,\" but the apartment felt dingy.  ',\n",
       " 'There was hair in the tub, the floor was dusty, and the comforter felt dirty as well.  ',\n",
       " 'The apartment was more than adequate for the stay and was clean and comfortable.\\r\\n\\r\\n',\n",
       " 'The apartment was quiet and clean.',\n",
       " 'Older apartment but clean.  ',\n",
       " 'Once again, it was clean and comfortable.',\n",
       " 'As a result, we had to make our own arrangements with the previous guest, the subsequent guests, and the cleaning lady -- all of which succeeded, more by luck than by planning.\\r\\n\\r\\n\\r\\n\\r\\n',\n",
       " 'The apartment is represented very accurately by the pictures and it is a clean and comfortable place.',\n",
       " 'The bedroom and bathroom were very clean and well taken care of.',\n",
       " 'It was clean, close to downtown, and met my needs while I was in Seattle.  ',\n",
       " 'Clean and quiet.',\n",
       " 'There was an overall mildew/moldy smell that perhaps came from the lack of air circulation and piled wet leaves right outside the windows.  ',\n",
       " 'The bathroom, and most importantly the bathtub, seemed clean.  ',\n",
       " \"There was just that mildewy smell we couldn't escape.  \",\n",
       " 'Only concern is that the bed was really squeaky, but overall the apartment was clean.',\n",
       " 'The apartment was clean and checking in was a smooth process.',\n",
       " 'As for the apartment, it was a clean and very cozy place.',\n",
       " \"Also we couldn't find an outlet in the bathroom, so we had to dry/straighten/curl our hair in the living room using our laptop camera as a mirror.\",\n",
       " 'The apartment is clean and convenient to the highway.',\n",
       " 'A few downsides were the lack of an outlet in the restroom and while the couch was comfortable but seemed dirty.',\n",
       " 'The apartment itself was tidy and even though there was a heat wave and no A/C, it was kept cool by being on the bottom floor and the host provided several fans to chill the space.',\n",
       " 'Great location and clean.',\n",
       " \"On your way up to the door you'll see tons of spiderwebs and dust.\",\n",
       " 'Place was neat',\n",
       " 'Great location, clean apartment, simple entry process.',\n",
       " 'This accommodation was easily accessible and we arrived to a spotlessly clean apartment.',\n",
       " 'The property was clean and comfortable.',\n",
       " \"It was clean overall, but dusty in areas--couch was old & worn, and I couldn't reach the outlet next to the bed (lamp was plugged in but stereo/alarm was unplugged).\",\n",
       " 'The apartment is clean and presents as advertised.',\n",
       " 'The apartment itself was very clean and nicely furnished.',\n",
       " 'Clean linens and towels were provided.',\n",
       " 'The space was very clean and it felt like my own apartment.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home258571_cleanliness_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**********************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_detail(sen_keywords, aspect_keywords):\n",
    "    score = 0\n",
    "    for token1 in sen_keywords:\n",
    "        for token2 in aspect_keywords:\n",
    "            if token1.similarity(token2) >= 0.7:\n",
    "                print(token1.text, token2.text, token1.similarity(token2))\n",
    "                score += 1\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = nlp(u\"Nick was very communicative and gracious enough to transport me to and from the light rail upon my arrival and departure, and went the extra mile by leaving me maps, recommendations, and even printed out a bus route based on where I'd told him I planned on going.\")\n",
    "aspect_keywords = nlp(' '.join(aspect_keywords_dic['cleanliness']))\n",
    "\n",
    "# print(len(sen_keywords), len(aspect_keywords))\n",
    "score_detail(h, aspect_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.648041676443703"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def word_similarity(w1, w2):\n",
    "    token1 = nlp(w1)\n",
    "    token2 = nlp(w2)\n",
    "    return token1.similarity(token2)\n",
    "\n",
    "word_similarity('scrubbing', 'clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Brief pre-processing logic for one sentence.\")\n",
    "# print(\"*\" * 93 + \"\\nAn example:\\n\" + \"-\" * 80 + \"\\nThe first sentence:\")\n",
    "# print(list(doc.sents)[0].text)\n",
    "\n",
    "# print(\"-\" * 93 + \"\\nSentence keywords got from keyword_extraction function:\")\n",
    "# sen_keywords = list(keyword_extraction(list(doc.sents)[0].text).keys())\n",
    "# print(sen_keywords)\n",
    "\n",
    "# print(\"-\" * 93 + \"\\nJoin sentence keywords together for further similarity use:\")\n",
    "# sen_keywords = ' '.join(sen_keywords)\n",
    "# print(sen_keywords)\n",
    "# print(\"-\" * 93)\n",
    "\n",
    "# **So, temporarily, I tried to use the count of the words in a sentance \n",
    "# that with lager than `0.7 `similarity score to determine the relevance.\n",
    "# And it works well for now.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
